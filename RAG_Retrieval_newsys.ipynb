{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6e1096-1f36-4711-a5c7-7612b6e771cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da79f95-3a6c-4fd5-8a58-012b891ede9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b2f1ef-234e-4677-aec9-7b3c5ebf8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c25884-248a-425d-b552-fccd4b9feb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "azure_model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30cea834-03a7-4955-9710-7ec80a8e8e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 12:29:31.374591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f9a50a-967d-432e-9ade-5221728167af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Distance, VectorParams\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "vector_size = len(embeddings.embed_query(\"sample text\"))\n",
    "\n",
    "if not client.collection_exists(\"test\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"test\",\n",
    "        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    "    )\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"test\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc6a1fe-d787-4307-836c-f839627d5f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0xbbee for key /x1098\n",
      "Multiple definitions in dictionary at byte 0xbbfe for key /x1099\n",
      "Multiple definitions in dictionary at byte 0xbc0e for key /x1098\n",
      "Multiple definitions in dictionary at byte 0xbc1e for key /x1099\n",
      "Multiple definitions in dictionary at byte 0xbc2e for key /x1098\n",
      "Multiple definitions in dictionary at byte 0xbc3e for key /x1099\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "all_docs = []\n",
    "for file in os.listdir(\"PDFs\"):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(os.path.join(\"PDFs\", file))\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe883cf1-35fc-43f9-ab2c-a27b94b16ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 2312 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(all_docs)\n",
    "print(f\"Split into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e79dfc9b-d847-42ff-a842-9f56a08ebea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3163909f315e48c0a4022d15c0e2c31a', 'f125d5189ba6414691bbc47720dd497c', 'd39a72413df3417984ab20aa5006341a']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae66391-91b3-4858-bfd2-26b6a01d634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sheet (user_input, to_print=True):\n",
    "    \"\"\"\n",
    "    Must be called alongside user input every time. Returns scores per pdf.\n",
    "    \"\"\"\n",
    "    results = vector_store.similarity_search_with_score(user_input, k=1000)\n",
    "    \n",
    "    pdf_best_scores = {}\n",
    "    for doc, score in results:\n",
    "        src = doc.metadata[\"source\"]\n",
    "        pdf_best_scores[src] = max(pdf_best_scores.get(src, 0), score)\n",
    "    \n",
    "    files = np.array(list(pdf_best_scores.keys()))\n",
    "    scores = np.array(list(pdf_best_scores.values()))\n",
    "    df = pd.DataFrame(np.concatenate((files.reshape(-1,1),scores.reshape(-1,1)), axis=1), columns=['1','2'])\n",
    "\n",
    "    if to_print:\n",
    "        print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02556841-4c04-48b3-ae87-33f80e4bebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "243fbc7e-c735-4958-b823-c1b122a59520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reranking(user_input, k=3):\n",
    "    df = score_sheet(user_input, to_print=False)\n",
    "    df_rerank = df.iloc[:k, 0].values\n",
    "\n",
    "    reranked_docs = []\n",
    "    for doc_path in df_rerank:\n",
    "        loader = PyPDFLoader(doc_path)\n",
    "        docs = loader.load()\n",
    "        reranked_docs.extend(docs)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "    reranked_splits = text_splitter.split_documents(reranked_docs)\n",
    "\n",
    "    query_vec = embeddings.embed_query(user_input)\n",
    "    similarity_values = []\n",
    "    for chunk in reranked_splits:\n",
    "        vec = embeddings.embed_query(chunk.page_content)\n",
    "        similarity_values.append(cosine_similarity(query_vec, vec))\n",
    "\n",
    "    similarity_values = np.sort(np.array(similarity_values))\n",
    "\n",
    "    best_docs = []\n",
    "    best_idx = np.array(similarity_values[:k], dtype=int)\n",
    "    for idx in best_idx:\n",
    "        best_docs.append(reranked_splits[idx])\n",
    "    return best_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d260375-61a7-4107-a7d1-b70894cd2173",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "reranking(\"What is a dog?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12cbbfe8-af18-47f9-9fe2-484342b610ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066656164931488"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"this is a dog?\"\n",
    "query1 = \"is this a dog\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "query_embedding1 = embeddings.embed_query(query1)\n",
    "\n",
    "cosine_similarity(query_embedding, query_embedding1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f69da54-8eec-4d77-9a82-d1dc9ea1c6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385016826056514"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is langchain\"\n",
    "query1 = \"what do you mean by langchain\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "query_embedding1 = embeddings.embed_query(query1)\n",
    "\n",
    "cosine_similarity(query_embedding, query_embedding1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12894a55-994f-445c-9bb4-360485d1d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "retrieval_cache = {}\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    for entry in retrieval_cache:\n",
    "        query_matching = cosine_similarity(query_embedding, embeddings.embed_query(entry))\n",
    "        if query_matching > 0.87:\n",
    "            print(\"Information found in cache...\")\n",
    "            return retrieval_cache[entry]\n",
    "    \n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    df1 = score_sheet(query, to_print=False)\n",
    "\n",
    "    if float(df1.iloc[0,1]) < 0.4:\n",
    "        print(\"Reranking ...\")\n",
    "        retrieved_docs = reranking(query)\n",
    "        \n",
    "    serialized = \"\\n\\n\".join(\n",
    "        f\"Source: {doc.metadata}\\nContent: {doc.page_content}\"\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "\n",
    "    score_sheet(query)\n",
    "    \n",
    "    result = (serialized, retrieved_docs)\n",
    "    retrieval_cache[query] = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fccc8356-614e-48ea-9c50-e5f8eda4834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.caches import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "tools = [retrieve_context]\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from PDF Documents.\"\n",
    "    \"Use the tool to help answer user queries. Mention to the user when you are using cached data.\"\n",
    ")\n",
    "\n",
    "agent = create_agent(azure_model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fce45c81-0add-498a-ad4a-6b1d70ea0212",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "query = (\n",
    "    \"What is a dog?\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    checkpointer=InMemorySaver(),\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc4dc749-fe70-4f4f-9fb1-83ad33ceff19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Prompt (type 'q' to quit, type 'n' for new conversation):  what is a cat?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is a cat?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_JQjVptJ2Vh5MOxsJDFXwuwDt)\n",
      " Call ID: call_JQjVptJ2Vh5MOxsJDFXwuwDt\n",
      "  Args:\n",
      "    query: what is a cat\n",
      "Reranking ...\n",
      "                                                    1                    2\n",
      "0                            PDFs/Dog - Wikipedia.pdf   0.3079954348898596\n",
      "1                         PDFs/Animal - Wikipedia.pdf   0.2896269783008171\n",
      "2               PDFs/Machine learning - Wikipedia.pdf  0.23762258063574188\n",
      "3        PDFs/Artificial intelligence - Wikipedia.pdf  0.22478535907707192\n",
      "4                        PDFs/Chatbot - Wikipedia.pdf  0.18483502718377834\n",
      "5                  PDFs/Heat transfer - Wikipedia.pdf  0.18462805948811495\n",
      "6           PDFs/Large language model - Wikipedia.pdf   0.1811874801589316\n",
      "7            PDFs/Supervised learning - Wikipedia.pdf  0.17601312907030672\n",
      "8   PDFs/Generative artificial intelligence - Wiki...  0.17231176686946537\n",
      "9             PDFs/Net-zero emissions - Wikipedia.pdf  0.15726544596524525\n",
      "10                 PDFs/Search engine - Wikipedia.pdf  0.14658409354847618\n",
      "11                     PDFs/LangChain - Wikipedia.pdf  0.12294102974799664\n",
      "12               PDFs/Albert Einstein - Wikipedia.pdf  0.12274695664689154\n",
      "13  PDFs/Retrieval-augmented generation - Wikipedi...  0.11788861958967253\n",
      "14              PDFs/Search algorithm - Wikipedia.pdf  0.11540730423280285\n",
      "15                 PDFs/Mass transfer - Wikipedia.pdf  0.11296595065389035\n",
      "16  PDFs/Intergovernmental Panel on Climate Change...  0.10021471380407256\n",
      "17               PDFs/Reynolds number - Wikipedia.pdf  0.09750394697463266\n",
      "18                  PDFs/Albert Camus - Wikipedia.pdf  0.08914934772728088\n",
      "19                PDFs/Nusselt number - Wikipedia.pdf  0.08126014477990258\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'producer': 'cairo 1.18.0 (https://cairographics.org)', 'creator': 'Mozilla Firefox 146.0.1', 'creationdate': '2026-01-09T12:43:12+05:30', 'source': 'PDFs/Dog - Wikipedia.pdf', 'total_pages': 50, 'page': 0, 'page_label': '1', 'start_index': 0}\n",
      "Content: Dog\n",
      "Temporal range: Late Pleistocene\n",
      "(14,200 years ago) to present[1]\n",
      "Conservation status\n",
      "Domesticated\n",
      "Scientiﬁc classiﬁcation\n",
      "Kingdom: Animalia\n",
      "Phylum: Chordata\n",
      "Class: Mammalia\n",
      "Order: Carnivora\n",
      "Family: Canidae\n",
      "Genus: Canis\n",
      "Species:C. familiaris\n",
      "Binomial name\n",
      "Canis familiaris\n",
      "Linnaeus, 1758[2]\n",
      "Synonyms[3]\n",
      "List\n",
      "Dog\n",
      "The dog (Canis familiaris or Canis lupus familiaris) is a\n",
      "domesticated descendant of the gray wolf. Also called the\n",
      "domestic dog, it was selectively bred from a population of\n",
      "wolves  during  the  Late  Pleistocene  by  hunter-gatherers.\n",
      "Dogs were the ﬁrst species to be domesticated over 14,000\n",
      "years ago, before the development of agriculture. Due to\n",
      "their long association with humans, dogs have gained the\n",
      "ability  to  thrive  on  a  starch-rich  diet  that  would  be\n",
      "inadequate for other canids.\n",
      "Dogs  have  been  bred  for  desired  behaviors,  sensory\n",
      "capabilities,  and  physical  attributes.  Dog  breeds  vary\n",
      "widely  in  shape,  size,  and  color.  They  have  the  same\n",
      "\n",
      "Source: {'producer': 'cairo 1.18.0 (https://cairographics.org)', 'creator': 'Mozilla Firefox 146.0.1', 'creationdate': '2026-01-09T12:43:12+05:30', 'source': 'PDFs/Dog - Wikipedia.pdf', 'total_pages': 50, 'page': 0, 'page_label': '1', 'start_index': 0}\n",
      "Content: Dog\n",
      "Temporal range: Late Pleistocene\n",
      "(14,200 years ago) to present[1]\n",
      "Conservation status\n",
      "Domesticated\n",
      "Scientiﬁc classiﬁcation\n",
      "Kingdom: Animalia\n",
      "Phylum: Chordata\n",
      "Class: Mammalia\n",
      "Order: Carnivora\n",
      "Family: Canidae\n",
      "Genus: Canis\n",
      "Species:C. familiaris\n",
      "Binomial name\n",
      "Canis familiaris\n",
      "Linnaeus, 1758[2]\n",
      "Synonyms[3]\n",
      "List\n",
      "Dog\n",
      "The dog (Canis familiaris or Canis lupus familiaris) is a\n",
      "domesticated descendant of the gray wolf. Also called the\n",
      "domestic dog, it was selectively bred from a population of\n",
      "wolves  during  the  Late  Pleistocene  by  hunter-gatherers.\n",
      "Dogs were the ﬁrst species to be domesticated over 14,000\n",
      "years ago, before the development of agriculture. Due to\n",
      "their long association with humans, dogs have gained the\n",
      "ability  to  thrive  on  a  starch-rich  diet  that  would  be\n",
      "inadequate for other canids.\n",
      "Dogs  have  been  bred  for  desired  behaviors,  sensory\n",
      "capabilities,  and  physical  attributes.  Dog  breeds  vary\n",
      "widely  in  shape,  size,  and  color.  They  have  the  same\n",
      "\n",
      "Source: {'producer': 'cairo 1.18.0 (https://cairographics.org)', 'creator': 'Mozilla Firefox 146.0.1', 'creationdate': '2026-01-09T12:43:12+05:30', 'source': 'PDFs/Dog - Wikipedia.pdf', 'total_pages': 50, 'page': 0, 'page_label': '1', 'start_index': 0}\n",
      "Content: Dog\n",
      "Temporal range: Late Pleistocene\n",
      "(14,200 years ago) to present[1]\n",
      "Conservation status\n",
      "Domesticated\n",
      "Scientiﬁc classiﬁcation\n",
      "Kingdom: Animalia\n",
      "Phylum: Chordata\n",
      "Class: Mammalia\n",
      "Order: Carnivora\n",
      "Family: Canidae\n",
      "Genus: Canis\n",
      "Species:C. familiaris\n",
      "Binomial name\n",
      "Canis familiaris\n",
      "Linnaeus, 1758[2]\n",
      "Synonyms[3]\n",
      "List\n",
      "Dog\n",
      "The dog (Canis familiaris or Canis lupus familiaris) is a\n",
      "domesticated descendant of the gray wolf. Also called the\n",
      "domestic dog, it was selectively bred from a population of\n",
      "wolves  during  the  Late  Pleistocene  by  hunter-gatherers.\n",
      "Dogs were the ﬁrst species to be domesticated over 14,000\n",
      "years ago, before the development of agriculture. Due to\n",
      "their long association with humans, dogs have gained the\n",
      "ability  to  thrive  on  a  starch-rich  diet  that  would  be\n",
      "inadequate for other canids.\n",
      "Dogs  have  been  bred  for  desired  behaviors,  sensory\n",
      "capabilities,  and  physical  attributes.  Dog  breeds  vary\n",
      "widely  in  shape,  size,  and  color.  They  have  the  same\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I retrieved some information to help answer your question. Based on that, a cat is not explicitly defined in the provided text. Would you like a general definition of a cat?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Prompt (type 'q' to quit, type 'n' for new conversation):  how can i use langchain to help in sustainability  research?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "how can i use langchain to help in sustainability  research?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Using LangChain to support sustainability research can be highly effective because it allows for the integration of large language models (LLMs) with various data sources, automation, and customization. Here are some ways you can leverage LangChain for sustainability research:\n",
      "\n",
      "1. Literature Review Automation:\n",
      "   - Automate the summarization of research papers, reports, and articles related to sustainability.\n",
      "   - Use LangChain to extract key themes, trends, and data from large documents.\n",
      "2. Data Collection and Integration:\n",
      "   - Build pipelines to gather data from APIs, websites, and databases relevant to environmental metrics, carbon footprints, or renewable energy statistics.\n",
      "   - Integrate this data with natural language understanding for analysis.\n",
      "3. Knowledge Base Creation:\n",
      "   - Develop an accessible knowledge base with structured and unstructured sustainability data.\n",
      "   - Enable querying natural language questions about sustainability topics.\n",
      "4. Decision Support Tools:\n",
      "   - Create applications that help policymakers and researchers simulate outcomes of different sustainability initiatives.\n",
      "   - Use LLMs to generate reports, policy recommendations, and impact assessments.\n",
      "5. Educational Resources:\n",
      "   - Develop interactive tutorials, FAQs, and learning modules on sustainability topics.\n",
      "6. Collaboration and Communication:\n",
      "   - Automate the drafting of grant proposals, project reports, and public communications.\n",
      "7. Monitoring and Reporting:\n",
      "   - Set up automated systems for ongoing monitoring of sustainability indicators and generating regular updates.\n",
      "\n",
      "Would you like a specific example or guidance on how to start building such a system with LangChain?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Prompt (type 'q' to quit, type 'n' for new conversation):  tell me using ources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "tell me using ources\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_4Z8XBqPcViNL3Vm88t4sHyXk)\n",
      " Call ID: call_4Z8XBqPcViNL3Vm88t4sHyXk\n",
      "  Args:\n",
      "    query: the sources from which the information in the document was derived\n",
      "  retrieve_context (call_vk4kfG4Uw7JBneYzb9x6CpcN)\n",
      " Call ID: call_vk4kfG4Uw7JBneYzb9x6CpcN\n",
      "  Args:\n",
      "    query: the references or sources cited in the document\n",
      "                                                    1                    2\n",
      "0   PDFs/Intergovernmental Panel on Climate Change...   0.4359803739871354\n",
      "1   PDFs/Retrieval-augmented generation - Wikipedi...  0.38541706742051995\n",
      "2                      PDFs/LangChain - Wikipedia.pdf   0.3267899869799341\n",
      "3                PDFs/Albert Einstein - Wikipedia.pdf  0.32653487791550284\n",
      "4                  PDFs/Search engine - Wikipedia.pdf   0.3243081217428323\n",
      "5              PDFs/Carbon accounting - Wikipedia.pdf    0.319076932721544\n",
      "6                  PDFs/Heat transfer - Wikipedia.pdf  0.31674080589894615\n",
      "7                         PDFs/Animal - Wikipedia.pdf   0.2999851320738357\n",
      "8        PDFs/Artificial intelligence - Wikipedia.pdf  0.29884231669712275\n",
      "9           PDFs/Large language model - Wikipedia.pdf  0.26753652969762926\n",
      "10            PDFs/Net-zero emissions - Wikipedia.pdf   0.2559358294409504\n",
      "11                           PDFs/Dog - Wikipedia.pdf  0.25071993312444435\n",
      "12                  PDFs/Albert Camus - Wikipedia.pdf  0.24544542904085914\n",
      "13                       PDFs/Chatbot - Wikipedia.pdf  0.24184424050309095\n",
      "14              PDFs/Machine learning - Wikipedia.pdf   0.2289417317765052\n",
      "15              PDFs/Search algorithm - Wikipedia.pdf   0.2249183505084088\n",
      "16  PDFs/Generative artificial intelligence - Wiki...  0.22203805117327413\n",
      "17               PDFs/Reynolds number - Wikipedia.pdf   0.2056638596936023\n",
      "18           PDFs/Supervised learning - Wikipedia.pdf  0.19331238739791204\n",
      "19                PDFs/Nusselt number - Wikipedia.pdf  0.15074670391431205\n",
      "20                 PDFs/Mass transfer - Wikipedia.pdf  0.13292052842598062\n",
      "                                                    1                    2\n",
      "0   PDFs/Intergovernmental Panel on Climate Change...  0.48580973538778793\n",
      "1                  PDFs/Heat transfer - Wikipedia.pdf  0.45040365469625787\n",
      "2        PDFs/Artificial intelligence - Wikipedia.pdf  0.41135040332432027\n",
      "3                  PDFs/Search engine - Wikipedia.pdf  0.41023637637772387\n",
      "4                PDFs/Albert Einstein - Wikipedia.pdf  0.40553873029909127\n",
      "5   PDFs/Retrieval-augmented generation - Wikipedi...   0.3958179796207787\n",
      "6              PDFs/Carbon accounting - Wikipedia.pdf   0.3934756519523764\n",
      "7                   PDFs/Albert Camus - Wikipedia.pdf  0.39300545261189546\n",
      "8                      PDFs/LangChain - Wikipedia.pdf   0.3785322384035497\n",
      "9   PDFs/Generative artificial intelligence - Wiki...  0.36450787513494437\n",
      "10            PDFs/Net-zero emissions - Wikipedia.pdf   0.3540685877468673\n",
      "11                       PDFs/Chatbot - Wikipedia.pdf   0.3333750528902293\n",
      "12              PDFs/Machine learning - Wikipedia.pdf  0.33226317463076704\n",
      "13          PDFs/Large language model - Wikipedia.pdf  0.29849408521342535\n",
      "14                           PDFs/Dog - Wikipedia.pdf   0.2740988223431301\n",
      "15                        PDFs/Animal - Wikipedia.pdf  0.27316999906042927\n",
      "16               PDFs/Reynolds number - Wikipedia.pdf   0.2608182197145791\n",
      "17           PDFs/Supervised learning - Wikipedia.pdf  0.24308040208564427\n",
      "18              PDFs/Search algorithm - Wikipedia.pdf  0.21786453628461788\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'producer': 'cairo 1.18.0 (https://cairographics.org)', 'creator': 'Mozilla Firefox 146.0.1', 'creationdate': '2026-01-09T12:41:19+05:30', 'source': 'PDFs/Intergovernmental Panel on Climate Change - Wikipedia.pdf', 'total_pages': 27, 'page': 7, 'page_label': '8', 'start_index': 798, '_id': '0c79bd97d21f405b8be77a53ff617088', '_collection_name': 'test'}\n",
      "Content: gender. Authors may include, in addition to researchers, personalities from the private sector and experts\n",
      "from NGOs.[55][56][57][58]\n",
      "The  IPCC  Bureau  or  Working  Group  Bureau  selects  the  authors  of  the  reports  from  government\n",
      "nominations. Lead authors of IPCC reports assess the available information about climate change based\n",
      "on published sources.[5][59] According to IPCC guidelines, authors should give priority to peer-reviewed\n",
      "sources.[5] Authors may refer to non-peer-reviewed sources (\"grey literature\"), if they are of suﬃcient\n",
      "quality.[5] These could include reports from government agencies and non-governmental organizations.\n",
      "Industry journals and model results are other examples of non-peer-reviewed sources.[5]\n",
      "Authors prepare drafts of a full report divided into chapters. They also prepare a technical summary of the\n",
      "report, and a summary for policymakers.[5]\n",
      "Each chapter has many authors to write and edit the material. A typical chapter has two coordinating lead\n",
      "\n",
      "Source: {'producer': 'cairo 1.18.0 (https://cairographics.org)', 'creator': 'Mozilla Firefox 146.0.1', 'creationdate': '2026-01-09T12:41:19+05:30', 'source': 'PDFs/Intergovernmental Panel on Climate Change - Wikipedia.pdf', 'total_pages': 27, 'page': 8, 'page_label': '9', 'start_index': 0, '_id': 'b053d21cd2874cb0acc54f8832d53aaf', '_collection_name': 'test'}\n",
      "Content: relevant expertise.\n",
      "There are generally three stages in the review process.[5] First comes an expert review of the ﬁrst draft of\n",
      "the chapters. The next stage is a review by governments and experts of the revised draft of the chapters\n",
      "and the ﬁrst draft of the Summary for Policymakers. The third stage is a government review of the revised\n",
      "Summary for Policymakers. Review comments and author responses remain in an open archive for at least\n",
      "ﬁve  years.  Finally,  government  representatives  together  with  the  authors  review  the  Summary  for\n",
      "Policymakers. They go through the Summary for Policymakers line by line to ensure it is a good summary\n",
      "of the underlying report. This ﬁnal review of the Summary of Policymakers takes place at sessions of the\n",
      "responsible working group or of the Panel.\n",
      "There are several types of endorsement that documents receive:\n",
      "▪ Approval - Material has been subject to detailed, line-by-line discussion and\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The information in the document is derived from sources related to the Intergovernmental Panel on Climate Change (IPCC) reports and Wikipedia. The sources include the official publications of the IPCC, which involve expert reviews, government reviews, and assessments based on published and peer-reviewed sources, as well as grey literature from government agencies and NGOs.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Prompt (type 'q' to quit, type 'n' for new conversation):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting PDF analyst.\n"
     ]
    }
   ],
   "source": [
    "i='1'\n",
    "while True:\n",
    "    user_input = input(\"Enter Prompt (type 'q' to quit, type 'n' for new conversation): \").strip()\n",
    "    \n",
    "    if user_input.lower() in [\"q\", \"quit\"]:\n",
    "        print(\"Exiting PDF analyst.\")\n",
    "        break\n",
    "\n",
    "    if user_input.lower() in [\"n\", \"new\"]:\n",
    "        print(\"What can I do for you?\")\n",
    "        i = str(int(i) + 1)\n",
    "        continue\n",
    "\n",
    "    steps = []\n",
    "    \n",
    "    for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    checkpointer=InMemorySaver(),\n",
    "    stream_mode=\"values\",\n",
    "    ):\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9365859-7bf5-4ee5-941b-338055f5823a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LangChain'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_cache.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
